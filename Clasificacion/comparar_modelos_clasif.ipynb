{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 0px 0px 15px 15px;\" src=\"https://machinelearningmastery.com/wp-content/uploads/2016/03/Compare-Machine-Learning-Algorithms.png\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "# <font color= #8A0829> Laboratorio de Modelado de Datos </font>\n",
    "#### <font color= #2E9AFE> `Martes y Viernes (Videoconferencia) de 13:00 - 15:00 hrs`</font>\n",
    "- <Strong> Sara Eugenia Rodríguez </Strong>\n",
    "- <Strong> Año </Strong>: 2024\n",
    "- <Strong> Email: </Strong>  <font color=\"blue\"> `cd682324@iteso.mx` </font>\n",
    "___\n",
    "\n",
    "\n",
    "### <font color= #2E9AFE> Tema: Comparación de modelos de Clasificación</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decidir cuál modelo de ML utilizar \n",
    "\n",
    "Decidir cuál modelo de machine learning utilizar sin necesidad de probar todos los modelos es una habilidad que se puede desarrollar haciendo preguntas específicas sobre los datos y el problema que se quiere resolver.\n",
    "\n",
    "**Preguntas sobre los Datos**\n",
    "\n",
    "1. **¿Cuál es la cantidad y calidad de los datos disponibles?**\n",
    "\n",
    "- ¿Cuántas instancias tienes en el conjunto de datos? Si tienes muchos datos, modelos complejos como Redes Neuronales o XGBoost pueden aprovecharlos bien. Si tienes pocos datos, modelos simples como Regresión Logística o SVM suelen ser más efectivos.\n",
    "- ¿Existen missing values o valores atípicos que puedan afectar el análisis? Modelos como Random Forest y XGBoost son más robustos frente a missing values y valores atípicos. Modelos lineales como Regresión Logística y SVM pueden necesitar más preprocesamiento.\n",
    "- ¿Qué tan balanceadas están las clases objetivo? En casos de clases desbalanceadas, considera XGBoost o Random Forest con un buen tuneo de hiperparámetros para lidiar con el desbalance. Modelos como SVM pueden funcionar bien, pero es crucial balancear las clases.\n",
    "\n",
    "2. **¿Cuántas características tengo y cómo se relacionan entre sí?**\n",
    "\n",
    "- ¿Cuántas características (columnas) tienes y cuál es su tipo?: Para un gran número de características, Random Forest y XGBoost suelen manejar la dimensionalidad mejor. Modelos como SVM pueden ser más lentos en casos de alta dimensionalidad.\n",
    "- ¿Qué relaciones existen entre las características? ¿Hay multicolinealidad entre algunas?: Si hay multicolinealidad, considera modelos como Regresión Logística (con regularización) o Redes Neuronales.\n",
    "- ¿Las características están en una escala comparable o necesitarías normalizarlas/estandarizarlas? Modelos lineales (Regresión Logística, SVM) y Redes Neuronales generalmente requieren datos estandarizados, mientras que Random Forest y XGBoost no son sensibles a la escala de las características.\n",
    "\n",
    "3. **¿Mis datos son numéricos, categóricos o una combinación de ambos?**\n",
    "\n",
    "- Numéricos: La mayoría de los modelos manejan bien datos numéricos.\n",
    "- Categóricos: Modelos basados en árboles pueden manejar variables categóricas de mejor forma.\n",
    "- Combinación: Si tienes una combinación, considera modelos como Random Forest o XGBoost que son más versátiles con diferentes tipos de datos.\n",
    "- ¿Tienes datos categóricos de alta cardinalidad?: XGBoost y Random Forest suelen manejar mejor categorías de alta cardinalidad.\n",
    "- ¿Requieres algún preprocesamiento especial, como para texto o imágenes?: Para texto o imágenes, Redes Neuronales son la opción adecuada.\n",
    "\n",
    "4. **Distribución y Ruido**\n",
    "\n",
    "- ¿Cuál es la distribución de cada característica?: Si las distribuciones son no normales o sesgadas, modelos no paramétricos como Random Forest y XGBoost pueden funcionar bien. Los modelos lineales pueden beneficiarse de transformaciones previas de las características.\n",
    "\n",
    "- ¿Existen características con muchos outliers?: Random Forest y XGBoost son generalmente más robustos ante muchos outliers en los datos. Modelos como Regresión Logística y SVM pueden ser sensibles a los outliers, especialmente en datos pequeños.\n",
    "\n",
    "- ¿Hay necesidad de reducir la dimensionalidad?: En alta dimensionalidad, considera SVM con kernel RBF o Random Forest, o bien reducir la dimensionalidad antes de aplicar Regresión Logística o Redes Neuronales.\n",
    "\n",
    "**Preguntas sobre el Problema**\n",
    "\n",
    "1. **¿Cuál es el objetivo principal del problema?**\n",
    "\n",
    "- ¿Es clasificación binaria o multiclase?: Para multiclase, Random Forest, XGBoost y Redes Neuronales suelen rendir bien. SVM también puede manejar multiclase, pero será más lento.\n",
    "\n",
    "- ¿Necesitas interpretar el modelo?: Regresión Logística y Random Forest son más interpretables. XGBoost y Redes Neuronales ofrecen alta precisión, pero son más difíciles de interpretar.\n",
    "\n",
    "2. **¿Qué tipo de relación esperas entre las variables independientes y la dependiente?**\n",
    "\n",
    "- ¿Esperas relaciones lineales o no lineales?: Para relaciones lineales, Regresión Logística y SVM son efectivos. Para relaciones no lineales, Redes Neuronales, Random Forest y XGBoost suelen capturar mejor esas complejidades.\n",
    "\n",
    "- ¿Existen interacciones complejas entre variables?: Modelos como Random Forest, XGBoost y Redes Neuronales pueden aprender interacciones complejas. Regresión Logística y SVM pueden necesitar ingeniería de características previa.\n",
    "\n",
    "3. **¿Cuánto tiempo y recursos computacionales tienes disponibles?**\n",
    "\n",
    "- ¿Cuál es la capacidad computacional disponible?: Redes Neuronales y XGBoost requieren más recursos; para computardoras o tiempos limitados, considera Regresión Logística o Random Forest.\n",
    "- ¿El modelo necesita tiempos de predicción rápidos?: Para predicciones en tiempo real, Regresión Logística y Random Forest suelen ser rápidos, mientras que XGBoost y Redes Neuronales pueden requerir optimización adicional.\n",
    "\n",
    "4. **¿Necesitas un modelo que generalice bien o estás más interesado en el ajuste al conjunto de datos actual?**\n",
    "\n",
    "- Generalización: Random Forest y XGBoost tienden a generalizar mejor.\n",
    "- Ajuste al Conjunto Actual: Modelos como regresión logística o árbol de decisión sencillo pueden ajustar bien los datos actuales, pero podrían sobreajustar si no se tiene cuidado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si no te fue sencillo elegir un solo modelo a implementar, comparar varios modelos de machine learning es necesario para poder encontrar cuál de todos los modelos es el más eficiente y tiene los resultados más precisos. \n",
    "\n",
    "Recordando que si la **variable de respuesta es categórica** entonces, este es un problema de **clasificación** y tenemos que usar modelos de clasificación para estimar los valores predichos. \n",
    "\n",
    "Como vimos, hay muchos modelos de clasificación candidatos. Nuestra tarea es encontrar el que sirva a nuestro propósito.\n",
    "\n",
    "Vamos a utilizar varias métricas para comparar los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Performance (Clasificación)\n",
    "\n",
    "\n",
    "**Matriz de confusión**\n",
    "\n",
    "Las métricas de performance de evaluación se basan en el número total de las siguientes variables:\n",
    "\n",
    "- True Positives (Verdaderos positivos): Salidas predecidas correctamente como la clase positiva\n",
    "- True Negatives (Verdaderos negativos): Salidas predecidas correctamente como la clase negativa\n",
    "- False Positives (Falsos positivos): Salidas predecidas incorrectamente como la clase positiva\n",
    "- False Negatives (Falsos negativos): Salidas predecidas incorrectamente como la clase negativa\n",
    " \n",
    " Que se observa en la siguiente matriz (matriz de confusión): \n",
    " \n",
    " <img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://cdn.prod.website-files.com/660ef16a9e0687d9cc27474a/662c42677529a0f4e97e4f96_644aea65cefe35380f198a5a_class_guide_cm08.png\" width=\"350px\" height=\"180px\" />\n",
    " \n",
    "Existen varias métricas de performance que se usan para evaluar qué tan efectivo es un modelo: \n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Medida de cuántas observaciones nuestro modelo predijo correctamente sobre el número total de observaciones. \n",
    "- NOTA: se ve afectada por datasets con la variable target imbalanceada\n",
    "\n",
    "**Precision**\n",
    "\n",
    "$$Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Mide cuántas observaciones nuestro modelo predijo correctamente sobre el número de predicciones correctas e incorrectas. \n",
    "- Funciona bien con datasets imbalanceados. \n",
    "\n",
    "**Recall (Sensitivity)**\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "*¿Qué hace?*\n",
    "- Mide cuántas observaciones nuestro modelo predijo correctamente sobre el número total de observaciones. \n",
    "- Funciona bien con datasets imbalanceados.\n",
    "\n",
    "     \n",
    " **F1-Score**\n",
    " \n",
    " $$F1 Score=\\frac{2*Recall*Precision}{Recall+Precision}$$\n",
    " \n",
    " *¿Qué hace?*\n",
    "- Es un balance entre el precisión y recall\n",
    "\n",
    "**¿Cuál elegir?**\n",
    "\n",
    "- Si tenemos datos balanceados, el Accuracy podría ser la métrica más apropiada para usar. \n",
    "\n",
    "- Si estuviéramos tratando de detectar si una manzana está envenenada, el objetivo es reducir el número de Falsos Negativos, porque esperamos no equivocarnos clasificando manzanas que están envenenadas. En este caso el **Recall** sería la mejor métrica de evaluación. \n",
    "\n",
    "- Si estamos tratando de predecir si es buena idea invertir en una acción de la bolsa, esperaríamos que nuestro modelo sea bueno. EN este caso el **Precision** sería la mejor métricca de evaluación ya que mide qué tan \"correcto\" es el modelo. \n",
    "\n",
    "- Si buscamos maximizar tanto el precision como el recall, entonces el F1 Score es la mejor métrica de evaluación. \n",
    "\n",
    "\n",
    "**ROC**\n",
    "\n",
    "La curva ROC es una representación visual del rendimiento del modelo en todos los thresholds.\n",
    "\n",
    "La curva ROC se dibuja calculando la tasa de verdaderos positivos (TPR) y una tasa de falsos positivos (FPR) en cada threshold posible. Un modelo perfecto que en algún Threshold tiene una TPR de 1.0 y una FPR de 0.0, puede estar representado por un punto en (0, 1) si se ignoran todos los demás thresholds, o bien de la siguiente manera:\n",
    "\n",
    " <img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://developers.google.com/static/machine-learning/crash-course/images/auc_1-0.png?hl=es-419\" width=\"350px\" height=\"180px\" />\n",
    " \n",
    " **AUC**\n",
    "\n",
    "El área bajo la curva ROC (AUC) representa la probabilidad de que el modelo, si se da un ejemplo positivo y negativo elegido al azar, clasificará el positivo mayor que el negativo.\n",
    "\n",
    "El AUC es una medida útil para comparar el rendimiento de dos modelos diferentes siempre y cuando el conjunto de datos esté equilibrado.\n",
    "\n",
    "<img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://developers.google.com/static/machine-learning/crash-course/images/auc_0-65.png?hl=es-419\n",
    "\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    " <img style=\"float: center; margin: 0px 0px 15px 15px;\" src=\"https://developers.google.com/static/machine-learning/crash-course/images/auc_0-93.png?hl=es-419\" width=\"350px\" height=\"180px\" />\n",
    "\n",
    "\n",
    "ROC y AUC de dos modelos hipotéticos. La curva en la segunda figura, con un AUC mayor, representa el mejor de los dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los Datos\n",
    "\n",
    "Tenemos un dataset de un estudio que se le hizo a varias personas con la finalidad de identificar qué factores contribuyen a que alguien tenga una enfermedad del corazón. \n",
    "\n",
    "Se tienen las siguientes variables:\n",
    "\n",
    "- masculino - Género del paciente\n",
    "- edad - Edad del paciente\n",
    "- educación - Nivel de educación del paciente en datos ordinales\n",
    "- currentSmoker: información sobre un paciente si es fumador\n",
    "- cigsPerDay - Cantidad de consumo si el paciente es fumador\n",
    "- BPMeds: si un paciente está tomando BP\n",
    "- prevalentStroke: estado sobre si un paciente ha tenido un accidente cerebrovascular\n",
    "- prevalentHyp - Estado de hipertensión predominante\n",
    "- diabetes - Estado de la diabetes\n",
    "- totChol - Nivel de colesterol\n",
    "- sysBP - Nivel de presión arterial\n",
    "- diaBP - Presión arterial diastólica\n",
    "- sysBP - Presión arterial sistólica\n",
    "- IMC - Índice de masa corporal\n",
    "- heartRate - Lectura de frecuencia cardíaca\n",
    "- glucosa - nivel de glucosa\n",
    "- TenYearCHD: target si sufrirá riesgo de enfermedad coronaria en los próximos diez años\n",
    "\n",
    "Basados en esas variables, queremos predecir si una persona va a tener problemas cardiovasculares en 10 años, por lo que variable a predecir es \"TenYearCHD\". \n",
    "\n",
    "Vamos a comparar los siguientes modelos:\n",
    "- Regresión logística\n",
    "- Bosques Aleatorios\n",
    "- Redes Neuronales\n",
    "- SVC\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "datos = pd.read_csv('framingham.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer la variable target \"TenYearCHD\" es numérica pero realmente es categórica por la definición del problema donde 1=presenta enfermedad cardiovascular y 0 = no presenta enfermedad cardiovascular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revisamos si hay datos nulos\n",
    "missing = pd.DataFrame(datos.isnull().sum(), columns=['Valores Nulos'])\n",
    "missing['Porcentaje'] = missing.div(datos.shape[0])*100\n",
    "missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí tenemos variables con datos nulos: glucose, BMI, totChol, BPMeds, cigsPerDay, education. Representan poco porcentaje de datos nulos por lo tanto no se eliminan las variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando estadísticas básicas con los datos\n",
    "datos_stats = datos.describe()\n",
    "datos_stats = datos_stats.transpose()\n",
    "datos_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizar la variable de salida\n",
    "sns.countplot(x=datos['TenYearCHD']).set_title(\"Cuenta de la variable de salida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['TenYearCHD'].value_counts()\n",
    "print(644/(644+3596))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la variable de salida tenemos un imbalanceo moderado, la mayoría de las observaciones son de personas que tienen menor riesgo a desarrollar enfermedades cardiovasculares en los próximos 10 años. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico de cada variable vs target\n",
    "import seaborn as sns\n",
    "count_col = ['male','currentSmoker','BPMeds','prevalentStroke','prevalentHyp','diabetes']\n",
    "\n",
    "fig, axes = plt.subplots(2,3, figsize=(10,6))\n",
    "fig.subplots_adjust(hspace=0.4,wspace=0.8)\n",
    "\n",
    "fig.suptitle('Countplot',fontsize=16)\n",
    "\n",
    "i=0\n",
    "n=0\n",
    "\n",
    "for x in count_col:\n",
    "    sns.countplot(x=datos[x],hue=datos['TenYearCHD'],ax=axes[i,n])\n",
    "    \n",
    "    if n < 2:\n",
    "        n+=1\n",
    "    else:\n",
    "        n=0\n",
    "        i+=1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos gráficos podemos concluir:\n",
    "\n",
    "- Pacientes masculinos tienen un riesgo ligeramente mayor\n",
    "- Un fumador tiene un riesgo ligeramente mayor\n",
    "- El paciente que toma medicación para BP tiene un riesgo mucho mayor\n",
    "- Los pacientes con antecedentes de accidentes cerebrovasculares prevalentes tienen un riesgo mucho mayor\n",
    "- Existe mayor riesgo entre hipertensión pavalente\n",
    "- Los pacientes con diabetes corren un mayor riesgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráfico de la edad vs el target\n",
    "plt.figure(figsize=(16,6))\n",
    "sns.countplot(x=datos['age'],hue=datos['TenYearCHD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El riesgo tiende a ser mayor a partir de los 45 años."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quitar filas con datos nulos que son pocos\n",
    "datos = datos.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separar X y Y\n",
    "X = datos.drop(columns='TenYearCHD', axis=0)\n",
    "y = datos['TenYearCHD']\n",
    "\n",
    "#Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                  test_size = 0.2,\n",
    "                                                  random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancear datos de salida usando algoritmo de SMOTE\n",
    "sm = SMOTE(random_state = 42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=y_train).set_title(\"Cuenta de la variable de salida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTAS:\n",
    "\n",
    "Para este problema de clasificación, analizaremos estas métricas de performance como una medida de qué tan bueno será nuestro modelo.\n",
    "\n",
    "1. Recall\n",
    "2. ROC-AUC\n",
    "\n",
    "Estamos analizando el recall aquí el costo de un falso positivo (paciente identificado falsamente con riesgo) no sería tan malo como dejar falsos negativos (que un paciente realmente esté en riesgo de enfermarse pero no se identifique).\n",
    "\n",
    "Nuestra métrica principal aquí serían los valores de recall. Mientras que la métrica de AUC ROC se encargaría de ver qué tan bien las probabilidades predichas pueden diferenciar entre las 2 clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos y sus hiperparámetros para GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'LogisticRegression': {'C': [1]},\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [10, 20]},\n",
    "    'SVM': {'C': [0.1, 1, 10], 'kernel': ['rbf']},\n",
    "    'XGBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los modelos a comparar\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas de score en las que nos vamos a enfocar\n",
    "scoring = {'Recall': make_scorer(recall_score), 'ROC AUC': 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV para encontrar el mejor modelo\n",
    "best_models = {}\n",
    "for model_name in models:\n",
    "    grid = GridSearchCV(models[model_name], params[model_name], cv=5, scoring=scoring, refit='Recall', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "    print(f\"Best {model_name}: {grid.best_params_}\")\n",
    "    print(f\"Recall: {grid.best_score_}, ROC AUC: {grid.cv_results_['mean_test_ROC AUC'][grid.best_index_]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar en los datos de prueba\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"\\n{model_name} - Test Recall: {recall:.3f}, Test ROC AUC: {roc_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos la curva ROC AUC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Elegimos el mejor modelo \n",
    "best_model_name = max(best_models, key=lambda name: roc_auc_score(y_test, best_models[name].predict_proba(X_test)[:, 1]))\n",
    "best_model = best_models[best_model_name]\n",
    "\n",
    "# Predecimos en términos de probabilidades la clase de salida\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculamos la curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Encontramos el thrshold optimo\n",
    "j_scores = tpr - fpr\n",
    "best_threshold_index = j_scores.argmax()\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "print(f\"El mejor Threshold: {best_threshold:.2f}\")\n",
    "\n",
    "# Graficamos\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.scatter(fpr[best_threshold_index], tpr[best_threshold_index], color='red', label=f'Best Threshold = {best_threshold:.2f}')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(f'ROC Curve para el mejor modelo: {best_model_name}')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando el mejor trheshold para hacer predicciones\n",
    "y_pred_custom_threshold = (y_proba >= best_threshold).astype(int)\n",
    "\n",
    "recall = recall_score(y_test, y_pred_custom_threshold)\n",
    "precision = precision_score(y_test, y_pred_custom_threshold)\n",
    "f1 = f1_score(y_test, y_pred_custom_threshold)\n",
    "accuracy = accuracy_score(y_test, y_pred_custom_threshold)\n",
    "\n",
    "print(f\"Evaluacion con el mejor threshold {best_threshold:.2f}:\")\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qué seguiría?\n",
    "\n",
    "Interpretabilidad: Si es posible, intenta interpretar el modelo. Por ejemplo, si usas un modelo de regresión lineal o un árbol de decisión, analiza la importancia de las variables.\n",
    "\n",
    "Documentación del modelo: Documenta el proceso de selección de características, optimización de hiperparámetros y evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el modelo entrenado\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "joblib.dump(best_model, 'mejor_modelo_clas.pkl')\n",
    "\n",
    "# Cargar el modelo en el futuro\n",
    "# mejor_modelo_cargado = joblib.load('mejor_modelo_clas.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizar el mejor modelo para crear predicciones con nuevos datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear nuevos datos\n",
    "X_new  = pd.DataFrame([[1, 28, 3.0, 0, 3.0, 0.0, 0, 0, 1, 200.0, 105.0, 80.0, 25.0,  65.0, 87.0]], \n",
    "                      columns=['male', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
    "       'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',\n",
    "       'diaBP', 'BMI', 'heartRate', 'glucose'])\n",
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Será propenso a enfermarse?\n",
    "\n",
    "ynew = best_model.predict(X_new)\n",
    "ynew_proba = best_model.predict_proba(X_new)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La persona no es propensa a enfermarse', ynew, \" ya que tiene una probabilidad de: \", ynew_proba, \"de ser propenso\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
